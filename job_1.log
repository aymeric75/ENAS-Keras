2021-07-14 13:34:35.111159: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0
2021-07-14 13:34:40.883615: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1
2021-07-14 13:34:40.931740: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected
2021-07-14 13:34:40.931824: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: r23g37
2021-07-14 13:34:40.931846: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: r23g37
2021-07-14 13:34:40.931983: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 460.32.3
2021-07-14 13:34:40.932062: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 460.32.3
2021-07-14 13:34:40.932077: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 460.32.3
2021-07-14 13:34:40.933104: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-07-14 13:34:40.958422: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:301] Initialize GrpcChannelCache for job worker -> {0 -> localhost:12345, 1 -> localhost:23456}
2021-07-14 13:34:40.962602: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:411] Started server with target: grpc://localhost:23456
2021-07-14 13:35:05.568941: E tensorflow/core/common_runtime/base_collective_executor.cc:243] BaseCollectiveExecutor::StartAbort Invalid argument: [_Derived_]Collective ops is aborted by: Shape mismatch in the collective instance 111. Op at device /job:worker/replica:0/task:0/device:CPU:0 expected shape [12000] but another member in the group expected shape [2,5,10,10]. This is likely due to different input shapes at different members of the collective op.
The error could be from a previous operation. Restart your program to reset.
Additional GRPC error information from remote target /job:worker/replica:0/task:0:
:{"created":"@1626262505.568796235","description":"Error received from peer ipv6:[::1]:12345","file":"external/com_github_grpc_grpc/src/core/lib/surface/call.cc","file_line":1056,"grpc_message":"[_Derived_]Collective ops is aborted by: Shape mismatch in the collective instance 111. Op at device /job:worker/replica:0/task:0/device:CPU:0 expected shape [12000] but another member in the group expected shape [2,5,10,10]. This is likely due to different input shapes at different members of the collective op.\nThe error could be from a previous operation. Restart your program to reset.","grpc_status":3}
num_replicas_in_sync : 2
number of replicas 2 : 2
Traceback (most recent call last):
  File "main.py", line 110, in <module>
    main()
  File "main.py", line 89, in main
    controller.compute_accuracies(5, 5, strategy, global_batch_size, print_file=0)
  File "/vsc-hard-mounts/leuven-data/339/vsc33965/NAS_Data/final_thesis/NAS/ENAS/ENAS-total/./Controller.py", line 784, in compute_accuracies
    model = self.get_compiled_cnn_model(cells_array)
  File "/vsc-hard-mounts/leuven-data/339/vsc33965/NAS_Data/final_thesis/NAS/ENAS/ENAS-total/./Controller.py", line 267, in get_compiled_cnn_model
    cell.generateCell( blocks_array, 'conv', num_cell=i )
  File "/vsc-hard-mounts/leuven-data/339/vsc33965/NAS_Data/final_thesis/NAS/ENAS/ENAS-total/./Cell.py", line 67, in generateCell
    new_block.construct()
  File "/vsc-hard-mounts/leuven-data/339/vsc33965/NAS_Data/final_thesis/NAS/ENAS/ENAS-total/./Block.py", line 104, in construct
    self.output = (self.comb)([(the_layers[self.op1])(self.inputs[self.input1]), (the_layers[self.op2])(self.inputs[self.input2])])
  File "/data/leuven/339/vsc33965/miniconda3/envs/PythonGPU/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py", line 969, in __call__
    return self._functional_construction_call(inputs, args, kwargs,
  File "/data/leuven/339/vsc33965/miniconda3/envs/PythonGPU/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py", line 1107, in _functional_construction_call
    outputs = self._keras_tensor_symbolic_call(
  File "/data/leuven/339/vsc33965/miniconda3/envs/PythonGPU/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py", line 840, in _keras_tensor_symbolic_call
    return self._infer_output_signature(inputs, args, kwargs, input_masks)
  File "/data/leuven/339/vsc33965/miniconda3/envs/PythonGPU/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py", line 878, in _infer_output_signature
    self._maybe_build(inputs)
  File "/data/leuven/339/vsc33965/miniconda3/envs/PythonGPU/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py", line 2625, in _maybe_build
    self.build(input_shapes)  # pylint:disable=not-callable
  File "/data/leuven/339/vsc33965/miniconda3/envs/PythonGPU/lib/python3.8/site-packages/tensorflow/python/keras/layers/convolutional.py", line 197, in build
    self.kernel = self.add_weight(
  File "/data/leuven/339/vsc33965/miniconda3/envs/PythonGPU/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py", line 639, in add_weight
    variable = self._add_variable_with_custom_getter(
  File "/data/leuven/339/vsc33965/miniconda3/envs/PythonGPU/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py", line 810, in _add_variable_with_custom_getter
    new_variable = getter(
  File "/data/leuven/339/vsc33965/miniconda3/envs/PythonGPU/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer_utils.py", line 127, in make_variable
    return tf_variables.VariableV1(
  File "/data/leuven/339/vsc33965/miniconda3/envs/PythonGPU/lib/python3.8/site-packages/tensorflow/python/ops/variables.py", line 260, in __call__
    return cls._variable_v1_call(*args, **kwargs)
  File "/data/leuven/339/vsc33965/miniconda3/envs/PythonGPU/lib/python3.8/site-packages/tensorflow/python/ops/variables.py", line 206, in _variable_v1_call
    return previous_getter(
  File "/data/leuven/339/vsc33965/miniconda3/envs/PythonGPU/lib/python3.8/site-packages/tensorflow/python/ops/variables.py", line 67, in getter
    return captured_getter(captured_previous, **kwargs)
  File "/data/leuven/339/vsc33965/miniconda3/envs/PythonGPU/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py", line 2111, in creator_with_resource_vars
    created = self._create_variable(next_creator, **kwargs)
  File "/data/leuven/339/vsc33965/miniconda3/envs/PythonGPU/lib/python3.8/site-packages/tensorflow/python/distribute/mirrored_strategy.py", line 535, in _create_variable
    return distribute_utils.create_mirrored_variable(
  File "/data/leuven/339/vsc33965/miniconda3/envs/PythonGPU/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_utils.py", line 306, in create_mirrored_variable
    value_list = real_mirrored_creator(**kwargs)
  File "/data/leuven/339/vsc33965/miniconda3/envs/PythonGPU/lib/python3.8/site-packages/tensorflow/python/distribute/mirrored_strategy.py", line 530, in _real_mirrored_creator
    v = next_creator(**kwargs)
  File "/data/leuven/339/vsc33965/miniconda3/envs/PythonGPU/lib/python3.8/site-packages/tensorflow/python/ops/variables.py", line 199, in <lambda>
    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)
  File "/data/leuven/339/vsc33965/miniconda3/envs/PythonGPU/lib/python3.8/site-packages/tensorflow/python/ops/variable_scope.py", line 2612, in default_variable_creator
    return resource_variable_ops.ResourceVariable(
  File "/data/leuven/339/vsc33965/miniconda3/envs/PythonGPU/lib/python3.8/site-packages/tensorflow/python/ops/variables.py", line 264, in __call__
    return super(VariableMetaclass, cls).__call__(*args, **kwargs)
  File "/data/leuven/339/vsc33965/miniconda3/envs/PythonGPU/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py", line 1584, in __init__
    self._init_from_args(
  File "/data/leuven/339/vsc33965/miniconda3/envs/PythonGPU/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py", line 1722, in _init_from_args
    initial_value = initial_value()
  File "/data/leuven/339/vsc33965/miniconda3/envs/PythonGPU/lib/python3.8/site-packages/tensorflow/python/distribute/collective_all_reduce_strategy.py", line 576, in initial_value_fn
    return collective_ops.broadcast_recv(initial_value.shape,
  File "/data/leuven/339/vsc33965/miniconda3/envs/PythonGPU/lib/python3.8/site-packages/tensorflow/python/ops/collective_ops.py", line 331, in broadcast_recv
    return gen_collective_ops.collective_bcast_recv(
  File "/data/leuven/339/vsc33965/miniconda3/envs/PythonGPU/lib/python3.8/site-packages/tensorflow/python/ops/gen_collective_ops.py", line 55, in collective_bcast_recv
    return collective_bcast_recv_eager_fallback(
  File "/data/leuven/339/vsc33965/miniconda3/envs/PythonGPU/lib/python3.8/site-packages/tensorflow/python/ops/gen_collective_ops.py", line 114, in collective_bcast_recv_eager_fallback
    _result = _execute.execute(b"CollectiveBcastRecv", 1, inputs=_inputs_flat,
  File "/data/leuven/339/vsc33965/miniconda3/envs/PythonGPU/lib/python3.8/site-packages/tensorflow/python/eager/execute.py", line 59, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.InvalidArgumentError: Collective ops is aborted by: [_Derived_]Collective ops is aborted by: Shape mismatch in the collective instance 111. Op at device /job:worker/replica:0/task:0/device:CPU:0 expected shape [12000] but another member in the group expected shape [2,5,10,10]. This is likely due to different input shapes at different members of the collective op.
The error could be from a previous operation. Restart your program to reset.
Additional GRPC error information from remote target /job:worker/replica:0/task:0:
:{"created":"@1626262505.568796235","description":"Error received from peer ipv6:[::1]:12345","file":"external/com_github_grpc_grpc/src/core/lib/surface/call.cc","file_line":1056,"grpc_message":"[_Derived_]Collective ops is aborted by: Shape mismatch in the collective instance 111. Op at device /job:worker/replica:0/task:0/device:CPU:0 expected shape [12000] but another member in the group expected shape [2,5,10,10]. This is likely due to different input shapes at different members of the collective op.\nThe error could be from a previous operation. Restart your program to reset.","grpc_status":3}
The error could be from a previous operation. Restart your program to reset. [Op:CollectiveBcastRecv]
